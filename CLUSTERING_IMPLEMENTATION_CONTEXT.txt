CLUSTERING IMPLEMENTATION CONTEXT - COMPLETE SPECIFICATION
==========================================================

## OVERVIEW
Implement clustering service to enable Latent Space tab in ExperimentPage.tsx.
The clustering service mirrors the expert routing system but uses cluster assignments instead of expert routing.

## CURRENT STATE
✅ PCA generation is working and integrated into finalize_session
✅ PCA features stored as features_pca128.parquet (23MB file with 47,808 records)  
✅ Clustering schema exists (backend/src/schemas/clustering.py)
✅ MultiSankeyView works with expert routing data
✅ Backend serving at localhost:8000 with health check working

## DATA FLOW UNDERSTANDING

### Expert Routing (WORKING):
1. Frontend calls: apiClient.analyzeRoutes(request)
2. Hits: POST /experiments/analyze-routes  
3. Uses: ExpertRouteAnalysisService
4. Returns: RouteAnalysisResponse with nodes/links for Sankey visualization

### Clustering (TO IMPLEMENT):
1. Frontend calls: apiClient.analyzeClusterRoutes(request) [NEW]
2. Hits: POST /experiments/analyze-cluster-routes [NEW] 
3. Uses: ClusterRouteAnalysisService [NEW]
4. Returns: Same RouteAnalysisResponse format but with cluster data

## KEY TYPE DEFINITIONS (FROM EXISTING CODE)

### Frontend Request:
```typescript
interface AnalyzeRoutesRequest {
  session_id: string
  window_layers: number[]        // e.g., [6, 7]  
  filter_config?: FilterConfig
  top_n_routes: number
}

// Need similar for clusters:
interface AnalyzeClusterRoutesRequest {
  session_id: string
  window_layers: number[]
  filter_config?: FilterConfig
  top_n_routes: number
  clustering_config: {
    pca_dimensions: number           // User configured, default 128
    clustering_method: string        // "kmeans", "hierarchical", "dbscan" 
    layer_cluster_counts: {[key: number]: number}  // K per layer
  }
}
```

### Frontend Response (SAME STRUCTURE):
```typescript
interface RouteAnalysisResponse {
  session_id: string
  window_layers: number[]
  nodes: SankeyNode[]      // Clusters instead of experts
  links: SankeyLink[]      // Flows between clusters  
  top_routes: TopRoute[]   // Most frequent cluster paths
  statistics: RouteStatistics
}

interface SankeyNode {
  name: string             // "L6C2" instead of "L6E12"
  id: string              
  layer: number           
  expert_id: number        // BECOMES: cluster_id: number
  token_count: number
  categories: string[]
  category_distribution: Record<string, number>
  specialization: string   // "Abstract concepts cluster"
  context_target_pairs: Array<{
    context: string
    targets: string[]
    target_count: number
  }>
}

interface SankeyLink {
  source: string          // "L6C2" 
  target: string          // "L7C1"
  value: number
  probability: number
  route_signature: string // "L6C2→L7C1" instead of "L6E12→L7E5"
  category_distribution: Record<string, number>
  token_count: number
}
```

## CLUSTERING DATA MAPPING

### From Expert to Cluster:
- Expert ID (0-31) → Cluster ID (0-K)
- Expert name "L6E12" → Cluster name "L6C2" 
- Highway signature "L6E12→L7E5→L8E3" → "L6C2→L7C1→L8C0"

### Data Sources:
- **Tokens**: data/lake/session_*/tokens.parquet 
- **PCA Features**: data/lake/session_*/features_pca128.parquet (NEW)
- **Routing**: data/lake/session_*/routing.parquet (for context, not used directly)

### Clustering Process:
1. Load features_pca128.parquet  
2. For each layer in window_layers:
   - Extract PCA features for that layer (target tokens only)
   - Take top N dimensions (from clustering_config.pca_dimensions)
   - Perform clustering with K clusters (from layer_cluster_counts[layer])
   - Generate clustering.parquet records
3. Build cluster trajectories across layers
4. Generate Sankey nodes/links matching expert routing format

## EXISTING SCHEMA REFERENCE

### ClusteringRecord (backend/src/schemas/clustering.py):
```python
@dataclass
class ClusteringRecord:
    probe_id: str               # Links to tokens and features
    layer: int                  # Layer number (0-23)
    token_position: int         # 0=context, 1=target
    cluster_id: int             # Assigned cluster ID 
    cluster_confidence: float   # Distance-based confidence
    pca_dimensions: int         # PCA components used for clustering
    clustering_method: str      # "kmeans", "hierarchical", "dbscan"
    num_clusters: int           # Total clusters in layer
    distance_to_centroid: float # Distance to cluster center
    silhouette_score: float     # Quality metric
    captured_at: str            # ISO timestamp
```

### Cluster Highway Signature:
```python
def cluster_highway_signature(clustering_records: List[ClusteringRecord], target_tokens_only: bool = True) -> str:
    # Returns: "L6C2→L7C5→L8C1"
```

## LATENT SPACE TAB INTEGRATION

### Current State (Placeholder):
```typescript
function LatentSpaceTab({
  sessionId, sessionData, filterState,
  primaryAxis, secondaryAxis,
  windowLayers,                    // [6, 7, 8] - user configured
  layerClusterCounts,             // {6: 8, 7: 8, 8: 8} - K per layer
  clusteringMethod,               // "kmeans"
  pcaDimensions                   // 128
}) {
  // Currently shows placeholder divs
  // NEEDS: MultiSankeyView calling cluster endpoint
}
```

### Target Implementation:
```typescript
// Replace placeholder with:
<MultiSankeyView
  sessionId={sessionId}
  sessionData={sessionData}
  filterState={filterState}
  primaryAxis={primaryAxis}
  secondaryAxis={secondaryAxis}
  // ... other props same as expert tab
  onNodeClick={(data) => handleSankeyClick('cluster', data)}
  onLinkClick={(data) => handleSankeyClick('trajectory', data)}
  apiEndpoint="analyze-cluster-routes"  // NEW PROP NEEDED
  clusteringConfig={{                   // NEW PROP NEEDED
    pca_dimensions: pcaDimensions,
    clustering_method: clusteringMethod,
    layer_cluster_counts: layerClusterCounts
  }}
/>
```

## IMPLEMENTATION FILES NEEDED

### 1. Backend Service:
**File**: backend/src/services/experiments/cluster_route_analysis.py
**Purpose**: Mirror expert_route_analysis.py but for clusters
**Key Methods**:
- analyze_session_cluster_routes() 
- _perform_clustering_for_layers()
- _build_cluster_sankey_data()
- _generate_cluster_statistics()

### 2. Backend API Endpoint:
**File**: backend/src/api/routers/experiments.py (ADD TO EXISTING)
**New Endpoint**: POST /experiments/analyze-cluster-routes
**Request**: AnalyzeClusterRoutesRequest  
**Response**: RouteAnalysisResponse (same format)

### 3. Frontend Types:
**File**: frontend/src/types/api.ts (ADD TO EXISTING)
**New Types**: 
- AnalyzeClusterRoutesRequest
- ClusteringConfig  

### 4. Frontend API Client:
**File**: frontend/src/api/client.ts (ADD TO EXISTING)
**New Method**: analyzeClusterRoutes()

### 5. Update LatentSpaceTab:
**File**: frontend/src/pages/ExperimentPage.tsx (MODIFY EXISTING)
**Change**: Replace placeholder with MultiSankeyView

### 6. Stepped PCA Plot Component:
**File**: frontend/src/components/charts/SteppedPCAPlot.tsx (NEW)
**Purpose**: Visualize token movement through 3D PCA space

## TECHNICAL DETAILS

### Clustering Algorithm Integration:
- Use scikit-learn (already installed)
- Support kmeans, hierarchical, DBSCAN
- Store PCA models from PCAGenerationService for consistency
- Handle edge cases (insufficient data, failed clustering)

### Data Consistency:
- Use same probe_id linking as expert routing
- Preserve category distributions and token mappings
- Generate meaningful cluster "specializations" 
- Calculate silhouette scores for quality metrics

### Performance Considerations:
- Cache clustering results (clustering.parquet)
- Only re-cluster when parameters change
- Use efficient numpy operations for PCA slicing
- Parallel processing for multiple layers

### Error Handling:
- Graceful fallback if PCA features missing
- Meaningful error messages for invalid cluster counts  
- Handle DBSCAN noise points (cluster_id = -1)

## TESTING APPROACH

### Verification Steps:
1. Test PCA feature loading from existing session
2. Verify clustering produces valid cluster assignments
3. Confirm cluster trajectories match expected format
4. Test API endpoint returns proper RouteAnalysisResponse
5. Verify MultiSankeyView renders cluster data correctly
6. Test different clustering parameters (K, method, PCA dims)
7. Ensure category distributions preserved in clustering

### Test Session:
- Use existing session_8abec226 (has PCA features generated)
- Window layers: [6, 7] for initial testing
- K=6 clusters per layer, kmeans, 128D PCA

## DEMO SCENARIOS

### Scenario 1: Sentiment Clustering
- Should show clusters specialized in positive/negative concepts
- Cluster trajectories should preserve sentiment through layers
- Category distributions should show sentiment bias per cluster

### Scenario 2: POS Clustering  
- Clusters should separate nouns/verbs/adjectives
- Cross-layer trajectories should show grammatical consistency
- Specialization labels should reflect POS categories

### Scenario 3: Semantic Clustering
- Related concepts (animals, tools) should cluster together
- Trajectories should show semantic coherence across layers
- Abstract vs concrete concept separation

## CRITICAL SUCCESS CRITERIA

1. **Data Compatibility**: Clustering produces same RouteAnalysisResponse format
2. **Visual Integration**: MultiSankeyView works seamlessly with cluster data  
3. **Parameter Control**: User can adjust K, method, PCA dimensions
4. **Performance**: Clustering completes in reasonable time (<30 seconds)
5. **Quality**: Meaningful cluster specializations and trajectories
6. **Robustness**: Handles edge cases without crashing

## NEXT STEPS

1. Create detailed implementation todo list
2. Implement ClusterRouteAnalysisService
3. Add API endpoint for cluster analysis  
4. Update frontend to use clustering data
5. Build SteppedPCAPlot component
6. Test end-to-end integration
7. Polish cluster specialization labeling