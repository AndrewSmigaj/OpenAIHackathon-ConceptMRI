# Concept MRI - Architecture Tracking Document
# Status: todo | in_progress | done | blocked
# Priority: critical | high | medium | low
#
# ✅ MAJOR MILESTONE: Complete MoE Data Capture System Working!
# - All 9/9 integration tests passing with real GPT-OSS-20B model
# - Session-based capture with coordinated schema writing
# - Highway analysis generating signatures like "L0E6→L1E28→L2E14"  
# - Data lake with 30 records per schema (routing, expert internal, expert output)
# - Adapted successfully to quantized Mxfp4GptOssExperts architecture

meta:
  project: "Concept MRI - OpenAI Hackathon"
  version: "1.4"
  target_model: "gpt-oss-20b (OpenAI MoE)"
  model_details:
    - "1.8B total parameters (inspected: not 21B as initially assumed)"
    - "24 layers, 32 experts per layer, K=4 routing (not K=1)" 
    - "Uses MXFP4 quantization, fits in 16GB GPU memory"
    - "Available at: openai/gpt-oss-20b on Hugging Face"
    - "Apache 2.0 license"
    - "Analysis Strategy: Capture K=4 routing, analyze top-1 expert per layer"
    - "CRITICAL: Quantized model uses Mxfp4GptOssExperts - no individual expert modules"
    - "Hook Strategy: MLP combined hook for routing + experts collective hook for processing"
    - "Individual expert analysis not possible - collective expert patterns only"
  timeline: "7 days"
  updated: "2025-01-06"
  constraints:
    - "Two token inputs only"
    - "Several thousand words max"
    - "User-supplied API keys for LLM labeling"
    - "K=4 routing: Capture all 4 experts, analyze top-1 weighted expert per layer"
    - "Highway paths: Top-1 expert chains (e.g. L6E2→L7E15→L8E7)"
    - "Future expansion: Full K=4 expert combination analysis available"

# Critical Workflow Clarifications
workflow:
  probe_vs_experiment:
    - "**Probes populate data lake:** Run MoE capture on contexts → write Parquet (routing + PCA128)"
    - "**Experiments analyze word lists:** Select word subsets from populated data for analysis"
    - "**NO probe re-running:** Experiments consume existing captures, never re-run probes"
    - "**LLM labeling:** Applied to BOTH cluster cards AND archetypal path narratives"

  data_flow:
    - "Probe: contexts → MoE routing → lake artifacts (reusable)"
    - "Experiment: word lists → highway selection → cohort export → clustering/CTA → labeling"
    - "Analysis: clusters get LLM labels, paths get LLM narratives"
    - "Dual Transformation Analysis:"
    - "  1) Expert Highway Routing: How contexts transform MoE routing patterns across experts"
    - "  2) Individual Highway Latent: Context→target transformation within specific highway's space"
    - "Multi-Experiment Demo: Run separate experiments to showcase each transformation type"

# Core Infrastructure & Setup
infrastructure:
  directory_structure:
    status: done
    priority: critical
    description: "Root project directory organization"
    layout: |
      OpenAIHackathon-ConceptMRI/
      ├── backend/               # Python backend
      │   ├── src/              # Source code
      │   ├── tests/            # Backend tests
      │   └── requirements.txt  # Python deps
      ├── frontend/             # React frontend
      ├── data/                 # Data storage
      │   ├── lake/            # Probe captures
      │   ├── experiments/     # Experiment artifacts
      │   └── models/          # MoE model cache
      ├── notebooks/           # Dev notebooks
      ├── samples/             # Test data
      ├── scripts/             # Setup/maintenance
      └── docker-compose.yml   # Container orchestration

  model_setup:
    status: done
    priority: critical
    description: "gpt-oss-20b model download and testing"
    tasks:
      - name: "System requirements check"
        status: done
        file: "scripts/check_system.py"
        notes: "RTX 5070 Ti 16GB confirmed adequate"
      - name: "Model download script"
        status: done
        file: "scripts/setup_gpt_oss_20b.py"
      - name: "Model download (20GB)"
        status: done
        notes: "Downloaded from openai/gpt-oss-20b"
      - name: "Basic model loading test"
        status: done
        file: "scripts/test_quantized_model.py"
        notes: "Working with MXFP4 quantization on RTX 5070 Ti (~5s load time, ~14GB GPU)"
      - name: "MoE architecture inspection"
        status: done
        file: "scripts/inspect_moe_structure.py"
        notes: "24 layers, 32 experts/layer, K=4 routing, GptOssTopKRouter class identified"
      - name: "Activation hook development"
        status: done
        files: ["scripts/test_routing_capture_fixed.py", "scripts/test_routing_capture.py", "scripts/test_routing_minimal.py"]
        notes: "EnhancedRoutingCapture class implemented for quantized MoE. MLP combined hook captures routing directly, experts collective hook captures post-expert processing."

  project_setup:
    status: done
    priority: critical
    tasks:
      - name: "Initialize repository structure"
        status: done
        files: ["README.md", "requirements.txt", "pyproject.toml"]
      - name: "Set up development environment"
        status: done
        files: [".env.example", "docker-compose.yml", "Makefile"]
      - name: "Configure logging and error handling"
        status: todo
        priority: critical
        files: ["backend/src/utils/logging.py", "backend/src/utils/errors.py"]
        hackathon_scope:
          logging:
            - "Single JSON logger with timestamps"
            - "Console output only (no file rotation for MVP)"
            - "Three levels: ERROR, INFO, DEBUG"
            - "Request timing and memory usage"
            - "MoE routing decisions and clustering progress"
          error_handling:
            - "Try/catch with context logging"
            - "Graceful degradation (skip failed clusters, continue)"
            - "User-friendly error messages in API responses"

  data_layer:
    status: done
    priority: critical
    description: "Parquet storage with integrated capture service and token position tracking"
    tasks:
      - name: "Data schemas and contracts"
        status: done
        files: ["backend/src/schemas/"]
        completed_files:
          - "backend/src/schemas/tokens.py" # Updated with capture_session_id
          - "backend/src/schemas/routing.py" # Updated with token_position tracking
          - "backend/src/schemas/expert_internal_activations.py" # Updated for quantized MoE collective experts
          - "backend/src/schemas/expert_output_states.py" # Updated with token_position
          - "backend/src/schemas/features_pca128.py" # For experiment-time PCA
          - "backend/src/schemas/capture_manifest.py" # Session metadata for UI integration
      - name: "Parquet I/O utilities"
        status: done
        files:
          - "backend/src/core/parquet_writer.py"
          - "backend/src/core/parquet_reader.py"
          - "backend/src/core/data_lake.py"
      - name: "Shared utilities"
        status: done
        files:
          - "backend/src/utils/numpy_utils.py"
          - "backend/src/utils/parquet_utils.py"
      - name: "Manifest and ID system"
        status: todo
        files: ["backend/src/core/manifests.py", "backend/src/core/ids.py", "backend/src/core/types.py"]

# Backend Services (Python FastAPI)
backend:
  api_server:
    status: todo
    priority: critical
    files: ["backend/src/api/main.py", "backend/src/api/routers/"]
    endpoints:
      # PROBES (atomic capture -> lake)
      - path: "/api/probes"
        method: "POST"
        status: todo
        priority: critical
        body: "{ session_name:str, contexts:[str], targets:[str], layers:[int] }"
        returns: "{ session_id, manifest, lake_paths }"
        description: "Create capture session and run batch MoE capture. Writes all schemas to data lake with coordinated BatchWriters."

      - path: "/api/probes"
        method: "GET"
        status: todo
        priority: high
        returns: "[{ capture_id, created_at, contexts:[str], layers:[int] }]"
        description: "List available captures."

      - path: "/api/probes/{id}"
        method: "GET"
        status: todo
        priority: high
        returns: "{ manifest, lake_paths }"
        description: "Fetch capture manifest & file paths."

      # EXPERIMENTS (consume captures -> highways/cohort/cluster/cta)
      - path: "/api/experiments"
        method: "POST"
        status: todo
        priority: critical
        body: "{ capture_id:str, label?:str }"
        returns: "{ experiment_id }"
        description: "Create an experiment bound to an existing capture. No capture re-run."

      - path: "/api/experiments/{id}/highways"
        method: "POST"
        status: todo
        priority: critical
        returns: "{ highways_json_path, stats, window_used:[int,int,int] }"
        description: "Compute ExpertHighways from the experiment's capture (first window auto-selected)."

      - path: "/api/experiments/{id}/cohort"
        method: "POST"
        status: todo
        priority: critical
        body: "{ highway_signature:'L6E2→L7E3→L8E1', contexts:[str], mode?:'single'|'multi' }"
        returns: "{ cohort_path }"
        description: "Export cohort for selected highway+context(s). Enhanced to support context-target filtering."

      - path: "/api/experiments/{id}/highway-analysis"
        method: "GET"
        status: todo
        priority: critical
        params: "{ highway_signature:str }"
        returns: "{ contexts_targets:{ [context]:{ targets:[str], share:float } } }"
        description: "Get (context, target) pairs that flow through specified highway. Simple data query."


      - path: "/api/experiments/{id}/cluster"
        method: "POST"
        status: todo
        priority: critical
        body: "{ algo:'kmeans'|'hierarchical', k_per_layer:{L6:int,...} }"
        returns: "{ models:[...], assignments_paths:[...], window_used:[int,int,int] }"
        description: "Cluster cohort features on the auto-selected first window."

      - path: "/api/experiments/{id}/cta"
        method: "POST"
        status: todo
        priority: critical
        returns: "{ paths_path, survival_path, window_used:[int,int,int] }"
        description: "CTA (macro paths + survival/confusion) on first window."

      - path: "/api/experiments/{id}/rules/ets"
        method: "POST"
        status: todo
        priority: high
        returns: "{ rules_path }"
        description: "Generate ETS rules (faithful thresholds + prec/cov + CIs)."
        
      - path: "/api/experiments/{id}/rules/clr"
        method: "POST"
        status: todo
        priority: high
        returns: "{ rules_path }"
        description: "Generate CLR rules (lineage rules + prec/cov)."

      - path: "/api/experiments/{id}/label"
        method: "POST"
        status: todo
        priority: high
        returns: "{ clusters_path }"
        description: "Generate LLM labels for clusters (short_label, dominant, secondary, outliers, provenance)."

      - path: "/api/experiments"
        method: "GET"
        status: todo
        priority: high
        returns: "[{ id, created_at, capture_id, label?, window_used?, last_stage? }]"
        description: "List experiments for quick open in UI."

      - path: "/api/experiments/{id}"
        method: "GET"
        status: todo
        priority: high
        returns: "{ manifest, artifact_paths }"
        description: "Manifest/artifact lookup for loaders."
        
      # EXPERT HIGHWAY ROUTING TRANSFORMATION
      - path: "/api/transform/routing-matrix"
        method: "POST"
        status: todo
        priority: high
        body: "{ capture_id:str, contexts:[str] }"
        returns: "{ labels:[str], matrix:[[float]], mode:'routing' }"
        description: "Expert Highway Routing Analysis: How different contexts transform MoE routing patterns."

      # INDIVIDUAL HIGHWAY LATENT TRANSFORMATION  
      - path: "/api/experiments/{id}/highway-latent-transform"
        method: "POST"
        status: todo
        priority: high
        body: "{ highway_signature:str, context_token:str, target_tokens:[str] }"
        returns: "{ transformation_data:[[float]], target_labels:[str], basis:'latent_space' }"
        description: "Individual Highway Latent Analysis: Context→target transformation within specific highway's space."

      # EXPERT INTERNAL CLUSTERING
      - path: "/api/experiments/{id}/expert-internal-clustering"
        method: "POST"
        status: todo
        priority: high
        body: "{ layer:int, expert_id:int, clustering_algo:'kmeans'|'hierarchical', k:int }"
        returns: "{ clusters, pca_3d_data, specialization_analysis, cluster_cards }"
        description: "Analyze individual expert's internal FF concept organization with 3D PCA and clustering."

      # EXPERT OUTPUT CLUSTERING + CTA INTEGRATION
      - path: "/api/experiments/{id}/expert-output-clustering"
        method: "POST"
        status: todo
        priority: high
        body: "{ clustering_algo:'kmeans'|'hierarchical', k:int, auto_cta:boolean }"
        returns: "{ clusters, pca_3d_data, cta_results?, trajectory_sankey_data }"
        description: "Cluster collective expert output latent space with optional real-time CTA integration."

      # LLM INSIGHTS AND REPORT GENERATION
      - path: "/api/experiments/{id}/llm-insights"
        method: "POST"
        status: todo
        priority: high
        body: "{ analysis_type:'summary'|'expert_specialization'|'trajectory_analysis'|'custom', custom_prompt?:str }"
        returns: "{ insights, generated_analysis, report_sections, visualizations }"
        description: "Generate AI-powered insights and analysis reports for expert and trajectory findings."

      - path: "/api/experiments/{id}/llm-insights/ask"
        method: "POST"
        status: todo
        priority: high
        body: "{ question:str, context_data?:object }"
        returns: "{ answer, supporting_evidence, related_findings }"
        description: "Custom question-answering about experiment analysis results."

  services:
    # PROBES
    integrated_capture_service:
      status: done
      priority: critical
      file: "backend/src/services/probes/integrated_capture_service.py"
      description: "Complete session-based MoE capture for quantized GPT-OSS-20B with coordinated schema writing."
      supporting_files: 
        - "backend/src/services/probes/routing_capture.py" # EnhancedRoutingCapture with quantized MoE hooks
        - "backend/src/services/probes/probe_ids.py" # Probe and session ID generation
        - "scripts/test_integrated_capture.py" # Comprehensive test validation
      features:
        - name: "Quantized MoE architecture adaptation"
          status: done
          notes: "Successfully adapted to Mxfp4GptOssExperts structure - no individual expert modules, collective processing only"
        - name: "MLP combined hook (routing + output capture)"
          status: done
          notes: "Single hook captures both routing computation and MLP output. Replicates router logic manually since router.forward() never called."
        - name: "Experts collective hook (post-expert processing)"
          status: done
          notes: "Captures collective expert processing output for latent analysis. Works with flattened tensor shapes."
        - name: "Expert highway extraction with top-1 from K=4 routing"
          status: done
          notes: "highway_signature() method creates L{layer}E{expert} signatures focusing on target tokens (position=1)"
        - name: "Session-based capture management"
          status: done
          notes: "Complete session lifecycle: create -> capture -> finalize. Supports batch processing of context-target pairs."
        - name: "Token position tracking for highway analysis"
          status: done
          notes: "All schemas updated with token_position field (0=context, 1=target) for proper highway analysis"
        - name: "Coordinated schema writing with BatchWriters"
          status: done
          notes: "SessionBatchWriters coordinates all 5 schemas with proper probe_id foreign key relationships"
        - name: "Data lake integration and validation"
          status: done
          notes: "Complete data flow: hooks -> schemas -> parquet files -> highway analysis. All tests passing."
        - name: "GPU memory management and error resilience"
          status: done
          notes: "Proper hook cleanup, CUDA memory clearing, graceful failure handling"
          status: todo
      dependencies: ["transformers", "bitsandbytes", "accelerate"]

    # EXPERIMENTS
    highways_service:
      status: todo
      priority: critical
      file: "backend/src/services/experiments/highways.py"
      description: "Compute P(Eℓ+1|Eℓ) using top-1 experts from K=4 routing data."
      features:
        - name: "First window auto-select & persist to experiment manifest"
          status: todo
        - name: "Top-1 expert transition probabilities P(E_top1_l+1|E_top1_l)"
          status: todo
          notes: "Use expert_top1_id field from routing schema for highway computation"
        - name: "Coverage and stickiness metrics (top-1 expert paths)"
          status: todo
        - name: "Highway signature format: L{layer}E{top1_expert} (e.g. L6E2→L7E15→L8E7)"
          status: todo
        - name: "ExpertHighways.json export with top-1 routing"
          status: todo
        - name: "Optional: K=4 full routing analysis for future expansion"
          status: todo
          notes: "Store full expert_top4_ids data for potential multi-expert highway analysis"

    cohort_service:
      status: todo
      priority: critical
      file: "backend/src/services/experiments/cohorts.py"
      description: "Select probe_ids by highway_signature+context(s); write cohort parquet in experiment. Supports both single-context and within-highway multi-context analysis."
      highway_signature_format: "L{layer}E{expert} notation (e.g., L6E2→L7E3→L8E1)"
      features:
        - name: "Highway signature matching"
          status: todo
        - name: "Single context cohort export (original workflow)"
          status: todo
        - name: "Multi-context cohort export (within-highway analysis)"
          status: todo
          notes: "Export cohort containing multiple contexts but constrained to same highway"
        - name: "Highway analysis: (context, target) pair enumeration"
          status: todo
          notes: "For Highway Panel display - which contexts and targets use this highway"
        - name: "Cohort manifest badges (highway_signature, context_tokens, mode)"
          status: todo

    cluster_service:
      status: todo
      priority: critical
      file: "backend/src/services/experiments/cluster/"
      description: "Cluster cohort features (first window only)."
      components:
        - name: "base.py (ClusterBackend interface)"
          status: todo
        - name: "kmeans.py (MiniBatch)"
          status: todo
        - name: "hierarchical.py (Ward)"
          status: todo
      features:
        - name: "k-per-layer"
          status: todo
        - name: "Model + assignments persistence"
          status: todo

    expert_internal_clustering_service:
      status: todo
      priority: high
      file: "backend/src/services/experiments/expert_internal_clustering.py"
      description: "Cluster individual expert's internal FF activations to understand expert specialization."
      features:
        - name: "Extract expert internal activations for specific layer+expert"
          status: todo
          notes: "Get FF intermediate states for Layer X, Expert Y"
        - name: "3D PCA analysis of expert internal concept organization"
          status: todo
        - name: "K-means/hierarchical clustering of expert internal patterns"
          status: todo
        - name: "Expert specialization analysis (what concepts this expert handles)"
          status: todo
        - name: "Generate expert internal cluster cards with LLM labeling"
          status: todo

    expert_output_clustering_service:
      status: todo
      priority: high
      file: "backend/src/services/experiments/expert_output_clustering.py"
      description: "Cluster collective expert output latent space and integrate with CTA analysis."
      features:
        - name: "Collect expert output states across layers (collective latent space)"
          status: todo
        - name: "3D PCA visualization of expert output latent space"
          status: todo
        - name: "Interactive clustering with real-time CTA integration"
          status: todo
          notes: "Clustering results automatically feed into CTA analysis"
        - name: "Concept trajectory analysis through clustered latent regions"
          status: todo
        - name: "Sankey diagram generation for cluster transitions"
          status: todo

    expert_clustering_service:
      status: todo
      priority: medium
      file: "backend/src/services/experiments/expert_clustering.py"
      description: "Cluster experts by usage patterns and analyze token paths through expert clusters."
      features:
        - name: "Expert usage pattern analysis"
          status: todo
          notes: "Analyze which experts are used together across tokens"
        - name: "Expert similarity clustering" 
          status: todo
          notes: "Cluster experts by co-activation patterns and routing behavior"
        - name: "Token path analysis through expert clusters"
          status: todo
          notes: "Track tokens that use same expert clusters vs those that diverge"
        - name: "Expert cluster transition visualization"
          status: todo
          notes: "Show how tokens move between expert clusters across layers"
        - name: "Expert specialization convergence analysis"
          status: todo
          notes: "Identify tokens that converge to same expert clusters (similar processing)"

    cta_service:
      status: todo
      priority: critical
      file: "backend/src/services/experiments/cta.py"
      description: "CTA macro paths + survival/confusion (≥5% coverage)."
      features:
        - name: "Paths + examples writer"
          status: todo
        - name: "Survival/confusion metrics"
          status: todo
        - name: "5% coverage filter"
          status: todo

    rules_service:
      status: todo
      priority: high
      files: ["src/services/experiments/rules/ets.py", "src/services/experiments/rules/clr.py"]
      description: "ETS (faithful) + CLR (lineage) for cluster cards."
      features:
        - name: "Explainable Threshold Similarity"
          status: todo
        - name: "Cluster Lineage Rules"
          status: todo
        - name: "Precision/coverage with CIs"
          status: todo

    labeling_service:
      status: todo
      priority: high
      file: "backend/src/services/experiments/labeling.py"
      description: "LLM + stats → cards AND archetypal path narratives. Two-stage process: 1) Label clusters, 2) Use cluster labels to generate path narratives."
      features:
        - name: "Cluster semantic labeling with ontology grouping"
          status: todo
          details: "Dominant/secondary/outlier analysis with structured JSON output"
        - name: "Archetypal path narrative generation"
          status: todo
          details: "Takes cluster labels + path info → generates conceptual journey narratives"
        - name: "Two-stage LLM workflow"
          status: todo
          details: "Stage 1: Cluster labeling → Stage 2: Path labeling (uses cluster results)"
        - name: "Provenance tracking (which LLM generated which labels)"
          status: todo
        - name: "Structured output validation"
          status: todo
          details: "Validate JSON schemas for both cluster and path labels"

    llm_insights_service:
      status: todo
      priority: high
      file: "backend/src/services/experiments/llm_insights.py"
      description: "AI-powered analysis and report generation for expert specialization and concept trajectory findings."
      features:
        - name: "Automated expert specialization analysis"
          status: todo
          notes: "Generate insights about what each expert has learned to handle"
        - name: "Context transformation pattern analysis"
          status: todo
          notes: "Analyze how different contexts change expert routing patterns"
        - name: "Concept trajectory narrative generation"
          status: todo
          notes: "Create coherent stories about concept evolution through latent space"
        - name: "Custom question answering about analysis results"
          status: todo
          notes: "Allow scientists to ask specific questions about their findings"
        - name: "Research report compilation and export"
          status: todo
          notes: "Generate comprehensive reports combining all analysis types"
        - name: "Multi-domain correlation insights"
          status: todo
          notes: "Find relationships between expert specialization, highway patterns, and latent trajectories"

    expert_routing_transform_service:
      status: todo
      priority: high
      file: "backend/src/services/transform/expert_routing.py"
      description: "Expert Highway Routing Transformation: How contexts change MoE routing patterns."
      features:
        - name: "routing_distribution(capture_id, context)"
          status: todo
        - name: "context_routing_similarity_matrix(contexts)"
          status: todo
        - name: "expert_transition_differences(context_a, context_b)"
          status: todo

    highway_latent_transform_service:
      status: todo
      priority: high
      file: "backend/src/services/transform/highway_latent.py"
      description: "Individual Highway Latent Transformation: Context→target analysis within highway's space."
      features:
        - name: "extract_highway_context_targets(experiment_id, highway_signature, context)"
          status: todo
          notes: "Find targets that pair with specific context in this highway"
        - name: "compute_context_target_trajectories(context, targets, highway_signature)"
          status: todo
          notes: "Analyze how context transforms target trajectories in highway's latent space"
        - name: "latent_transformation_clustering(context_target_cohort)"
          status: todo
          notes: "Cluster on context to show target trajectory shifts"

    bundle_service:
      status: todo
      priority: low
      file: "backend/src/services/bundle.py"
      description: "Experiment bundling and replay"
      features:
        - name: "Zip experiment directory"
          status: todo
        - name: "Manifest validation"
          status: todo
        - name: "Replay without hidden state"
          status: todo

# Frontend (React + TypeScript)
frontend:
  setup:
    status: todo
    priority: critical
    description: "React + Vite + TypeScript + Tailwind"
    files: ["frontend/package.json", "frontend/vite.config.ts", "frontend/tailwind.config.js"]

  components:
    workspace_page:
      status: todo
      priority: critical
      file: "frontend/src/pages/WorkspacePage.tsx"
      features:
        - name: "New Probe"
          status: todo
        - name: "New Experiment (choose capture)"
          status: todo
        - name: "Open Experiment"
          status: todo
        - name: "Recent experiments"
          status: todo

    new_probe_dialog:
      status: todo
      priority: critical
      file: "frontend/src/components/NewProbeDialog.tsx"
      description: "Atomic probe capture; writes to lake; shows output paths."

    experiment_flow:
      status: todo
      priority: critical
      file: "frontend/src/components/ExperimentFlow.tsx"
      steps:
        - name: "Select Capture & Inputs"
          status: todo
          notes: "Pick an existing capture; select contexts/targets subset if desired."
        - name: "Expert Highways"
          status: todo
          notes: "Compute from capture; auto-select first window; show Sankey."
        - name: "Context-Target Highway Analysis (NEW)"
          status: todo
          notes: "Click highway → Context Transformation View shows context-target pairs. First demo: one context → one target list."
        - name: "Export Context-Target Cohort"
          status: todo
          notes: "Export cohort filtered by highway + context + targets for transformation analysis."
        - name: "Context Transformation Clustering"
          status: todo
          notes: "Cluster on first context to analyze how context transforms target trajectories in latent space."
        - name: "Transformation Shift Analysis"
          status: todo
          notes: "Compare how different contexts shift target token trajectories within same highway's computational pathway."
        - name: "Explore & Label"
          status: todo
          notes: "Enhanced Latent Sankey showing context→target transformations, Cluster Cards with context-specific patterns."

    expert_explorer:
      status: todo
      priority: critical
      file: "frontend/src/components/ExpertExplorer.tsx"
      features:
        - name: "Expert Sankey visualization (ECharts)"
          status: todo
          library: "echarts"
        - name: "Context filter (1 or 2 contexts from capture)"
          status: todo
        - name: "Diff toggle (ΔP on edges + Top Δ table)"
          status: todo
        - name: "Badges: Highway Signature + Context"
          status: todo
        - name: "Expert Card tabs (Overview|Clusters|PCA3D|Rules)"
          status: todo
        - name: "Token List panel with Export Cohort"
          status: todo
        - name: "Run clustering button"
          status: todo

    highway_panel:
      status: todo
      priority: critical
      file: "frontend/src/components/HighwayPanel.tsx"
      description: "Context Transformation View for analyzing how contexts transform target trajectories within highways."
      features:
        - name: "Highway selection from Expert Sankey clicks"
          status: todo
          notes: "Click highway edge → open Context Transformation View for that signature"
        - name: "Context→Target pairs display"
          status: todo
          notes: "Show context-target pairs that flow through this highway"
          format: |
            Highway: L6E2→L7E3→L8E1 (Context Transformation View)
            Context "the" → Target List: ["cat", "dog", "house"] (45% coverage)
            Context "a" → Target List: ["cat", "dog", "tree"] (32% coverage)
            [First Demo: Focus on single context → single target list]
        - name: "Context-target cohort export"
          status: todo
          notes: "Export cohort containing only context-target pairs for transformation clustering"
        - name: "Transformation clustering trigger"
          status: todo
          notes: "Cluster on first context to show how context shifts target trajectories in latent space"
        - name: "Context comparison visualization"
          status: todo
          notes: "Show how different contexts transform same targets differently within highway"

    latent_explorer:
      status: todo
      priority: critical
      file: "frontend/src/components/LatentExplorer.tsx"
      features:
        - name: "Window badge (read-only, Next/Prev disabled)"
          status: todo
        - name: "k-per-layer controls (first window only)"
          status: todo
        - name: "Latent Sankey + Path Drawer + Cluster Cards"
          status: todo

    visualizations:
      sankey_charts:
        status: todo
        priority: high
        file: "frontend/src/components/charts/SankeyChart.tsx"
        library: "echarts"
        features:
          - name: "Expert highway flow visualization"
            status: todo
          - name: "Latent cluster flow visualization"
            status: todo
          - name: "Interactive edge selection"
            status: todo

      pca_3d:
        status: todo
        priority: medium
        file: "frontend/src/components/charts/PCA3D.tsx"
        library: "plotly"
        features:
          - name: "3D scatter plot of PCA128 features"
            status: todo
          - name: "Cluster color coding"
            status: todo
          - name: "Interactive exploration"
            status: todo

    cards:
      cluster_cards:
        status: todo
        priority: high
        file: "frontend/src/components/cards/ClusterCard.tsx"
        description: "Population + ETS (faithful) & CLR (lineage); LLM labels (dominant/secondary/outliers + provenance)"
        features:
          - name: "Population statistics"
            status: todo
          - name: "ETS rules (faithful thresholds + prec/cov + CIs)"
            status: todo
          - name: "CLR rules (lineage rules + prec/cov)"
            status: todo
          - name: "LLM-generated labels with provenance"
            status: todo
            format: "{ short_label, dominant, secondary, outliers, breakdown }"
          - name: "Dominant/secondary/outlier examples"
            status: todo
          - name: "Dominant/secondary/outlier token examples"
            status: todo

  pages:
    expert_routing_transform:
      status: todo
      priority: high
      file: "frontend/src/pages/ExpertRoutingTransform.tsx"
      description: "Expert Highway Routing Transformation: How contexts change MoE routing patterns."
      features:
        - name: "Routing similarity heatmap (ECharts)"
          status: todo
        - name: "Context comparison controls"
          status: todo
        - name: "Expert transition difference visualization"
          status: todo

# Core Algorithms
algorithms:
  window_selection:
    status: todo
    priority: critical
    description: "Auto-select first CTA window deterministically"
    implementation: "backend/src/algorithms/window_selection.py"
    algorithm: |
      def select_first_window(captured_layers):
          for L in sorted(captured_layers):
              if {L, L+1, L+2}.issubset(captured_layers):
                  return (L, L+1, L+2)
          raise ValueError("Need three consecutive layers")

  expert_highways:
    status: todo
    priority: high
    description: "Compute expert transition probabilities"
    implementation: "backend/src/algorithms/expert_analysis.py"
    metrics:
      - "P(Expert_l+1 | Expert_l)"
      - "Coverage percentage"
      - "Stickiness score"
      - "Ambiguity percentage"

  concept_trajectory:
    status: todo
    priority: critical
    description: "CTA analysis on selected cohort"
    implementation: "backend/src/algorithms/cta.py"
    features:
      - "Macro path computation"
      - "Survival analysis"
      - "Confusion matrices"
      - "Path coverage filtering (≥5%)"

# CLIs (thin wrappers; stdout prints output paths)
cli:
  probe:
    status: todo
    priority: medium
    file: "backend/src/cli/probe.py"
    command: "cmri probe --contexts ctx.csv --targets targets.csv --layers 6,7,8"

  exp_new:
    status: todo
    priority: medium
    file: "backend/src/cli/exp_new.py"
    command: "cmri exp-new --capture <capture_id>"

  exp_highways:
    status: todo
    priority: medium
    file: "backend/src/cli/exp_highways.py"
    command: "cmri exp-highways --exp <id>"

  exp_cohort:
    status: todo
    priority: medium
    file: "backend/src/cli/exp_cohort.py"
    command: 'cmri exp-cohort --exp <id> --highway "L6E2→L7E3→L8E1" --context "the"'

  exp_cluster:
    status: todo
    priority: medium
    file: "backend/src/cli/exp_cluster.py"
    command: "cmri exp-cluster --exp <id> --algo kmeans --k-per-layer L6=3 L7=4 L8=3"

  exp_cta:
    status: todo
    priority: medium
    file: "backend/src/cli/exp_cta.py"
    command: "cmri exp-cta --exp <id>"

  exp_rules:
    status: todo
    priority: medium
    file: "backend/src/cli/exp_rules.py"
    command: "cmri exp-rules --exp <id> --mode ets|clr"

  exp_label:
    status: todo
    priority: medium
    file: "backend/src/cli/exp_label.py"
    command: "cmri exp-label --exp <id>"

  transform_matrix:
    status: todo
    priority: medium
    file: "backend/src/cli/transform_matrix.py"
    command: "cmri transform-matrix --capture <capture_id> --contexts the,a,an"

# Data Schemas
schemas:
  tokens:
    status: done
    priority: critical
    file: "backend/src/schemas/tokens.py"
    fields: ["probe_id","context_text","target_text","context_token_id","target_token_id"]
    notes: "Simple index table linking probe_id to context-target pairs. MVP version without freq_bin/pos_guess."

  routing:
    status: done
    priority: critical
    file: "backend/src/schemas/routing.py"
    fields: ["probe_id","layer","expert_top4_ids","expert_top4_weights","expert_top1_id","expert_top1_weight","gate_entropy","routing_aux_loss","captured_at"]
    removed_fields: ["routing_weights","expert_output"]
    notes: "K=4 routing capture implemented with top-1 extraction. Includes validation and helper methods."

  features_pca128:
    status: done
    priority: critical
    file: "backend/src/schemas/features_pca128.py"
    fields: ["probe_id","layer","pca128"]
    notes: "Simplified PCA features schema for MVP. Version tracking deferred."

  expert_internal_activations:
    status: done
    priority: high
    file: "backend/src/schemas/expert_internal_activations.py"
    fields: ["probe_id","layer","expert_id","ff_intermediate_state","activation_dims","captured_at"]
    notes: "Expert internal FF activations implemented with validation and analysis methods"

  expert_output_states:
    status: done
    priority: high
    file: "backend/src/schemas/expert_output_states.py"
    fields: ["probe_id","layer","expert_output_state","post_expert_dims"]
    notes: "Collective expert output states implemented with cosine similarity and normalization methods"

  expert_internal_clusters:
    status: todo
    priority: high
    file: "backend/src/schemas/expert_internal_clusters.py"
    fields: ["experiment_id","layer","expert_id","cluster_id","cluster_center","population","specialization_label","pca_3d_coords"]
    notes: "Individual expert internal clustering results with 3D PCA coordinates"

  expert_output_clusters:
    status: todo
    priority: high
    file: "backend/src/schemas/expert_output_clusters.py"
    fields: ["experiment_id","cluster_id","cluster_center","population","concept_trajectory_label","pca_3d_coords","cta_integration_data"]
    notes: "Collective expert output clustering results with CTA integration data"

  llm_insights:
    status: todo
    priority: high
    file: "backend/src/schemas/llm_insights.py"
    fields: ["experiment_id","insight_type","generated_at","llm_model","insights_text","supporting_data","report_sections","visualization_configs"]
    notes: "LLM-generated insights and analysis reports with supporting evidence"

  capture_manifest:
    status: todo
    priority: critical
    file: "backend/src/schemas/capture_manifest.py"
    fields: ["schema_version","capture_id","model_hash","contexts","layers","created_at"]

  cohort_manifest:
    status: todo
    priority: critical
    file: "backend/src/schemas/cohort_manifest.py"
    fields: ["schema_version","experiment_id","capture_id","highway_signature","context_tokens","target_tokens","cohort_mode","created_at"]
    cohort_modes:
      - name: "single_context"
        description: "Original workflow - single context analysis within highway"
      - name: "context_target_transformation"
        description: "Context-target transformation analysis - cluster on context to analyze target trajectory shifts"
      - name: "multi_context_highway"
        description: "Multi-context analysis for comparative transformation study"
    notes: "context_tokens and target_tokens arrays support context→target pairing for transformation analysis"

  experiment_manifest:
    status: todo
    priority: critical
    file: "backend/src/schemas/experiment_manifest.py"
    fields: ["schema_version","experiment_id","capture_id","window_used","clustering","created_at"]

  clustering:
    status: todo
    priority: critical
    file: "backend/src/schemas/clustering.py"
    fields: ["experiment_id", "layer", "cluster_id", "centroid", "population"]
    cluster_labeling_scheme:
      format: "L{layer}E{expert}C{cluster}{granularity}"
      examples: 
        - "L1E3C2M" (Layer 1, Expert 3, Cluster 2, Macro)
        - "L1E3C2m" (Layer 1, Expert 3, Cluster 2, micro)
      description: "Hierarchical identifier for cluster cards with macro/micro granularity"

  paths:
    status: todo
    priority: high
    file: "backend/src/schemas/paths.py"
    fields: ["path_signature", "coverage", "survival_rate", "examples"]

# Testing & Validation
testing:
  unit_tests:
    status: todo
    priority: medium
    coverage_target: "80%"
    files: ["tests/test_capture.py", "tests/test_clustering.py", "tests/test_cta.py"]

  integration_tests:
    status: in_progress
    priority: medium
    completed_tests:
      - name: "Parquet round-trip test"
        file: "scripts/test_capture_simulation.py"
        status: done
        notes: "Validates multi-layer capture with probe_id linkage"
    scenarios:
      - "End-to-end capture → highways → cohort → CTA"
      - "Window auto-selection edge cases"
      - "k-per-layer clustering validation"

  acceptance_tests:
    status: todo
    priority: high
    criteria:
      - "Capture: row counts match probes × layers"
      - "Expert Highways: edges sum correctly"
      - "Clustering: k-per-layer refreshes visualizations"
      - "Latent Explorer: ≥5% coverage paths rendered"
      - "Bundle: replay restores exact state"

# Deployment & DevOps
deployment:
  docker:
    status: todo
    priority: medium
    files: ["Dockerfile", "docker-compose.yml"]
    services: ["api", "frontend", "gpu-worker"]

  monitoring:
    status: todo  
    priority: low
    features:
      - "GPU memory monitoring"
      - "API response times"
      - "Error rate tracking"

# Demo Scenarios (Critical for Hackathon)
demo_scenarios:
  single_highway_single_context:
    status: todo
    priority: critical
    description: "Core demo: exploring a single highway with a single context token"
    flow:
      - "New Probe → capture contexts/targets"
      - "New Experiment → select capture"
      - "Expert Highways → auto-select first window"
      - "Click highway edge → Token List with badges"
      - "Export Cohort for that highway+context"
      - "Clustering/CTA → k-per-layer controls"
      - "Latent Explorer → Sankey (macro→micro) + Cluster Cards"

  two_experts_different_contexts:
    status: todo
    priority: high
    description: "Comparison demo: exploring two different experts with different context tokens"
    flow:
      - "Use existing capture with multiple contexts"
      - "Expert Explorer → Context filter (select 2 contexts)"
      - "Enable Diff toggle → show ΔP edges + Top Δ table"
      - "Compare expert routing patterns between contexts"
      - "Export cohorts for different highways"
      - "Side-by-side cluster analysis"

  expert_routing_transformation_analysis:
    status: todo
    priority: high
    description: "Expert Highway Routing Transformation: How contexts change MoE expert routing patterns"
    flow:
      - "Expert Routing Transform page → load capture contexts"
      - "Routing similarity heatmap → compare context routing patterns" 
      - "Expert transition differences → visualize how contexts change expert highways"
      - "Click patterns → navigate to specific context experiment"
      - "Demonstrate how context transforms MoE routing decisions"

  individual_highway_latent_analysis:
    status: todo
    priority: critical
    description: "Individual Highway Latent Transformation: Context→target analysis within highway's space"
    flow:
      - "Expert Highways → click specific highway edge (e.g., L6E2→L7E3→L8E1)"
      - "Highway panel opens → shows context→target pairs using this highway"
      - "Select context 'the' → shows target list ['cat', 'dog', 'house']"
      - "Export highway-specific cohort → filtered by highway+context+targets"
      - "Run latent transformation clustering → cluster on context to show target trajectory shifts" 
      - "Visualize how context transforms target trajectories within this highway's latent space"
      - "Demonstrates context-driven transformation constrained to specific computational pathway"

# Documentation
documentation:
  api_docs:
    status: todo
    priority: medium
    description: "FastAPI auto-generated OpenAPI docs"

  user_guide:
    status: todo
    priority: low
    file: "docs/user_guide.md"
    sections: ["Getting Started", "Expert Explorer", "Latent Explorer"]

  demo_recordings:
    status: todo
    priority: critical
    description: "Record all three demo scenarios for hackathon presentation"
    videos:
      - "Single highway exploration (core workflow)"
      - "Two-expert comparison with diff toggle"
      - "Transformation matrix → focused analysis"

# Dependencies & Environment
dependencies:
  python:
    version: "3.11"
    core: ["fastapi", "uvicorn", "transformers", "torch"]
    ml: ["scikit-learn", "numpy", "pandas"] 
    storage: ["pyarrow", "duckdb"]
    quantization: ["bitsandbytes", "accelerate"]
    status: todo

  frontend:
    node_version: "18+"
    core: ["react", "typescript", "vite", "tailwindcss"]
    charts: ["echarts", "plotly.js"]
    status: todo

# Risk Mitigation
risks:
  gpu_memory:
    severity: high
    mitigation: "NF4 quantization + micro-batch floor=4"
    status: todo

  timeline_pressure:
    severity: medium
    mitigation: "First window only constraint"
    status: planned

  model_compatibility:
    severity: medium
    mitigation: "Flexible MoE detection and hooks"
    status: todo

# LLM Labeling Prompt Template (v1.4)
llm_labeling:
  cluster_labeling_prompt:
    template: |
      You are labeling a cluster of words from a language model's latent space.
      Task: provide a concise human-readable label and a structured breakdown.
      
      Input:
      - Cluster tokens: {token_list}
      - Population stats: {stats_summary}
      
      Instructions:
      1. Group by higher-order ontology (examples): 
         - Animate objects (animals, people, living beings)
         - Inanimate objects (vehicles, tools, artifacts, places, food items, …)
         - Abstract concepts (qualities, emotions, ideas, relations)
         - Function words (pronouns, determiners, auxiliaries, prepositions, …)
         - Other
      2. Identify dominant meaning, secondary meanings, and outliers.
      3. Return:
         - short_label (2–5 words)
         - breakdown (counts or %)
         - outliers list
      4. If uncertain, short_label = "Unknown" and return raw groups only.
      
      Output (JSON):
      {
        "short_label": "Animate Objects (Animals)",
        "dominant": "Animals",
        "secondary": ["Vehicles"],
        "outliers": ["sandwich"],
        "breakdown": {"Animals": 6, "Vehicles": 2, "Food": 1}
      }

  archetypal_path_labeling_prompt:
    template: |
      You are creating narrative labels for archetypal paths in a neural network's concept trajectory analysis.
      Task: Generate a coherent narrative that describes the conceptual journey through expert clusters.
      
      Input:
      - Path signature: {path_signature}
      - Cluster labels along path: {cluster_labels}
      - Coverage percentage: {coverage}
      - Example tokens: {example_tokens}
      
      Instructions:
      1. Analyze the progression of cluster labels from start to end of the path
      2. Identify the conceptual transformation or journey represented
      3. Create a narrative that explains WHY this path exists (what linguistic/semantic pattern it captures)
      4. Use the cluster labels as anchor points in your narrative
      5. Keep narratives concise but informative (2-4 sentences)
      
      Output (JSON):
      {
        "path_narrative": "Concrete nouns evolve through spatial relationships to abstract locational concepts",
        "transformation_type": "Semantic abstraction",
        "key_transition": "Physical objects → Spatial relations → Abstract location",
        "linguistic_pattern": "Noun phrase processing with increasing abstraction"
      }